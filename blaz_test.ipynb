{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.GNN_Decoder import GNN_Decoder\n",
    "import src.gnn_models as gnn\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "import stim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = \"models/circuit_level_noise/d3/d3_d_t_3.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and export parameters\n",
    "_CODE_SIZE=3\n",
    "_REPETITIONS=3\n",
    "## Training settings\n",
    "_NUM_ITERATIONS=3\n",
    "_BATCH_SIZE=10\n",
    "_LEARNING_RATE=0.00001\n",
    "_MANUAL_SEED=12345\n",
    "## Benchmark\n",
    "_BENCHMARK=1\n",
    "## Buffer settings\n",
    "_BUFFER_SIZE=10\n",
    "_REPLACEMENTS_PER_ITERATION=2\n",
    "# test_size is len(error_rate) * batch_size * test_size\n",
    "_TEST_SIZE=1\n",
    "## Graph settings\n",
    "_NUM_NODE_FEATURES=5\n",
    "_EDGE_WEIGHT_POWER=2\n",
    "_M_NEAREST_NODES=6\n",
    "_USE_CUDA=0\n",
    "_USE_VALIDATION=1\n",
    "## Criterion\n",
    "_CRITERION = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN_params = {\n",
    "    'model': {\n",
    "        'class': gnn.GNN_7,\n",
    "        'num_classes': 1, # 1 output class for two-headed model\n",
    "        'loss': _CRITERION,\n",
    "        'num_node_features': _NUM_NODE_FEATURES,\n",
    "        'initial_learning_rate': _LEARNING_RATE,\n",
    "        'manual_seed': _MANUAL_SEED,\n",
    "    },\n",
    "    'graph': {\n",
    "        'num_node_features': _NUM_NODE_FEATURES,\n",
    "        'm_nearest_nodes': _M_NEAREST_NODES,\n",
    "        'power': _EDGE_WEIGHT_POWER,\n",
    "    },\n",
    "    'cuda': _USE_CUDA,\n",
    "    'save_path': \"test/test.pt\", \n",
    "    'save_prefix': \"test\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_7(\n",
       "  (graph1): GraphConv(5, 32)\n",
       "  (graph2): GraphConv(32, 128)\n",
       "  (graph3): GraphConv(128, 256)\n",
       "  (graph4): GraphConv(256, 512)\n",
       "  (graph5): GraphConv(512, 512)\n",
       "  (graph6): GraphConv(512, 256)\n",
       "  (graph7): GraphConv(256, 256)\n",
       "  (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lin2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lin4): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = torch.load(_PATH, weights_only=False, map_location=torch.device('cpu'))\n",
    "decoder = GNN_Decoder(GNN_params)\n",
    "decoder.load_training_history(attributes)\n",
    "decoder.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaulate_model(decoder, graph_data, save_to=None):\n",
    "    loader = DataLoader(graph_data, batch_size=1000)\n",
    "    decoder.model.eval()\n",
    "    for data in loader:\n",
    "        data.batch = data.batch.to(data.x.device)\n",
    "        prediction = decoder.model(data.x, data.edge_index, data.edge.attr, data.batch)\n",
    "        target = data.y\n",
    "\n",
    "        if save_to is not None:\n",
    "            torch.save((prediction, target), save_to)\n",
    "        else:\n",
    "            return prediction, target\n",
    "\n",
    "\n",
    "\n",
    "def generate_test_batch(test_size):\n",
    "    '''Generates a test batch at one test error rate'''\n",
    "    # Keep track of trivial syndromes\n",
    "    correct_predictions_trivial = 0\n",
    "\n",
    "    stim_data_list, observable_flips_list = [], []\n",
    "\n",
    "    # repeat each experiments multiple times to get enough non-empty \n",
    "    # syndromes. This number decreases with increasing p\n",
    "    stim_data, observable_flips = sampler.sample(shots =  test_size, separate_observables = True)\n",
    "    # remove empty syndromes:\n",
    "    # (don't count imperfect X(Z) in second to last time)\n",
    "    non_empty_indices = (np.sum(stim_data, axis = 1) != 0)\n",
    "    stim_data_list.extend(stim_data[non_empty_indices, :])\n",
    "    observable_flips_list.extend(observable_flips[non_empty_indices])\n",
    "    # count empty instances as trivial predictions: \n",
    "    correct_predictions_trivial += len(observable_flips[~ non_empty_indices])\n",
    "    # if there are more non-empty syndromes than necessary\n",
    "    stim_data_list = stim_data_list[: test_size]\n",
    "    observable_flips_list = observable_flips_list[: test_size]\n",
    "    buffer = generate_batch(stim_data_list, observable_flips_list,\n",
    "                            detector_coordinates, mask, m_nearest_nodes, power)\n",
    "    # convert list of numpy arrays to torch Data object containing torch GPU tensors\n",
    "    test_batch = []\n",
    "    for i in range(len(buffer)):\n",
    "        X = torch.from_numpy(buffer[i][0]).to(device)\n",
    "        edge_index = torch.from_numpy(buffer[i][1]).to(device)\n",
    "        edge_attr = torch.from_numpy(buffer[i][2]).to(device)\n",
    "        y = torch.from_numpy(buffer[i][3]).to(device)\n",
    "        test_batch.append(Data(x=X, edge_index=edge_index, edge_attr=edge_attr, y = y))\n",
    "    return test_batch, correct_predictions_trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment variables\n",
    "_distance = 3\n",
    "_time_steps = _distance\n",
    "_error_rate = 0.1\n",
    "_test_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = stim.Circuit.generated(\n",
    "    \"surface_code:rotated:memory_z\",\n",
    "    rounds=_distance,\n",
    "    distance=_distance,\n",
    "    after_clifford_depolarization=_error_rate,\n",
    "    after_reset_flip_probability=_error_rate,\n",
    "    befire_measure_flip_probability=_error_rate,\n",
    "    before_round_data_depolarization=_error_rate,\n",
    ")\n",
    "\n",
    "detector_coordinates = circuit.get_detector_coordinates()\n",
    "detector_coordinates = np.array(list(detector_coordinates.values()))\n",
    "# rescale space like coordinates:\n",
    "detector_coordinates[:, : 2] = detector_coordinates[:, : 2] / 2\n",
    "# convert to integers\n",
    "detector_coordinates = detector_coordinates.astype(np.uint8)\n",
    "\n",
    "sampler = circuit.compile_detector_sampler()\n",
    "\n",
    "factor = 50\n",
    "\n",
    "\n",
    "stim_data, observable_flips = sampler.sample(shots = _test_size, separate_observables = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
